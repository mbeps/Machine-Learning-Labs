{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset into Training Set & Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `X_train` - Matrix of Features of the training set\n",
    "- `X_test` - Matrix of Features of the testing set\n",
    "- `y_train` - Dependent Variable Vector of the training set\n",
    "- `y_test` - Dependent Variable Vector of the testing set\n",
    "\n",
    "- `train_test_set(matrix_of_features, dependent_variable_vector, test_size=), random_state=)` returns a tuple with the split dataset\n",
    "  - `test_size` - size of the test set given in decimal, the default is 0.25 test (leaving 0.75 for training set)\n",
    "  - `random_state` - a seed given so that the random split is consistent across multiple runs\n",
    "  - The dataset is split into:\n",
    "    - `X_train`, `X_test`, `y_train`, `y_test`\n",
    "    - The spit is done at random (pseudo-random) as there could potentially be an order in the labels (matrix of features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Documentation**\n",
    "```py\n",
    "(function) train_test_split: (*arrays: Any, test_size: Any | None = None, train_size: Any | None = None, random_state: Any | None = None, shuffle: bool = True, stratify: Any | None = None) -> list[Any | list]\n",
    "Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.\n",
    "\n",
    "Read more in the User Guide <cross_validation>.\n",
    "\n",
    "Parameters\n",
    "*arrays : sequence of indexables with same length / shape[0]\n",
    "    Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
    "\n",
    "test_size : float or int, default=None\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n",
    "\n",
    "train_size : float or int, default=None\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.\n",
    "\n",
    "random_state : int, RandomState instance or None, default=None\n",
    "    Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. See Glossary <random_state>.\n",
    "\n",
    "shuffle : bool, default=True\n",
    "    Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.\n",
    "\n",
    "stratify : array-like, default=None\n",
    "    If not None, data is split in a stratified fashion, using this as the class labels. Read more in the User Guide <stratification>.\n",
    "\n",
    "Returns\n",
    "splitting : list, length=2 * len(arrays)\n",
    "    List containing train-test split of inputs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix of Features / Labels for Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix of Features / Labels for Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependent Variable Vector for Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependent Variable Vector for Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All machine learning models in `scikit-learn` are implemented in their own classes, which are parts of modules\n",
    "- The K Nearest Neighbours classification algorithm is implemented in the `KNeighborsClassifier` class in the neighbors module\n",
    "- Before we can use the model, we need to instantiate the class into an object.\n",
    "- This is when we will set any parameters of the model\n",
    "\tThe single parameter of the `KNeighborsClassifier` is the number of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1) # n_neighbors is the number of neighbors to use (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A test iris object is created with the matrix of features (labels) filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[5, 2.9, 1, 0.2]]) # sample data to predict\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction about the test object is made to determine the species of iris\n",
    "  - Prediction returns the class of the species of iris which is the index of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = knn.predict(X_new) # predict the class of the new data point\n",
    "print(prediction) # prints the predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prediction (index of the class) is used to find the name associated with that that class index\n",
    "  - `iris['target_names']` returns all the the names of the classes -> `['setosa' 'versicolor' 'virginica']`\n",
    "  - `iris['target_names'][prediction]` returns the name of the specific class ->  `['setosa' 'versicolor' 'virginica'][0]` -> `'setosa'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['target_names']) # print all the names of the classes\n",
    "print(iris['target_names'][prediction]) # print the name of the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a prediction for an iris in the test data and compare it against its label (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test) # predict the class of the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Accuracy of Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of the model can be measured \n",
    "- How much of the sample matches the current dataset\n",
    "  -  fraction of flowers for which the right species was predicted\n",
    "- There are 2 ways of measuring accuracy, both of which return the same value:\n",
    "  - [Numpy Mean](#numpy-mean)\n",
    "  - [K-Nearest Neighbour](#k-nearest-neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred == y_test) # calculate the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test) # calculate the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking If Both Method Return the Same Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_pred == y_test) == knn.score(X_test, y_test)) # check if the two methods give the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a317dd932dec76e8fdc8987ca60af4062f347c78c20ca5292cf26c8b2836138"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
