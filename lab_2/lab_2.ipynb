{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset into Training Set & Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Documentation**\n",
    "```py\n",
    "(function) train_test_split: (*arrays: Any, test_size: Any | None = None, train_size: Any | None = None, random_state: Any | None = None, shuffle: bool = True, stratify: Any | None = None) -> list[Any | list]\n",
    "Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.\n",
    "\n",
    "Read more in the User Guide <cross_validation>.\n",
    "\n",
    "Parameters\n",
    "*arrays : sequence of indexables with same length / shape[0]\n",
    "    Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
    "\n",
    "test_size : float or int, default=None\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n",
    "\n",
    "train_size : float or int, default=None\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.\n",
    "\n",
    "random_state : int, RandomState instance or None, default=None\n",
    "    Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. See Glossary <random_state>.\n",
    "\n",
    "shuffle : bool, default=True\n",
    "    Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.\n",
    "\n",
    "stratify : array-like, default=None\n",
    "    If not None, data is split in a stratified fashion, using this as the class labels. Read more in the User Guide <stratification>.\n",
    "\n",
    "Returns\n",
    "splitting : list, length=2 * len(arrays)\n",
    "    List containing train-test split of inputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `X_train` - Matrix of Features of the training set\n",
    "- `X_test` - Matrix of Features of the testing set\n",
    "- `y_train` - Dependent Variable Vector of the training set\n",
    "- `y_test` - Dependent Variable Vector of the testing set\n",
    "\n",
    "- `train_test_set(matrix_of_features, dependent_variable_vector, test_size=), random_state=)` returns a tuple with the split dataset\n",
    "  - The Matrix of Features (labels) and Dependent Variable Vector must be separated\n",
    "  - `test_size` - size of the test set given in decimal, the default is 0.25 test (leaving 0.75 for training set)\n",
    "  - `random_state` - a seed given so that the random split is consistent across multiple runs\n",
    "  - The dataset is split into:\n",
    "    - `X_train`, `X_test`, `y_train`, `y_test`\n",
    "    - `train_test_split` returns a list which is then unpacked into the 4 variables\n",
    "    - The spit is done at random (pseudo-random) as there could potentially be an order in the labels (matrix of features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris() # load the iris dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], random_state=0) # 75% training and 25% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix of Features / Labels for Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix of Features / Labels for Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependent Variable Vector for Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependent Variable Vector for Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All machine learning models in `scikit-learn` are implemented in their own classes, which are parts of modules\n",
    "- The K Nearest Neighbours classification algorithm is implemented in the `KNeighborsClassifier` class in the neighbors module\n",
    "- Before we can use the model, we need to instantiate the class into an object.\n",
    "- This is when we will set any parameters of the model\n",
    "\tThe single parameter of the `KNeighborsClassifier` is the number of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1) # n_neighbors is the number of neighbors to use (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the k-nearest neighbors classifier from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train) # fit the model using the training data and training targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data to Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A test iris object is created with the matrix of features (labels) filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[5, 2.9, 1, 0.2]]) # sample data to predict\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction about the test object is made to determine the species of iris\n",
    "  - Prediction returns the class of the species of iris which is the index of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = knn.predict(X_new) # predict the class of the new data point\n",
    "print(prediction) # prints the predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The prediction (index of the class) is used to find the name associated with that that class index\n",
    "  - `iris['target_names']` returns all the the names of the classes -> `['setosa' 'versicolor' 'virginica']`\n",
    "  - `iris['target_names'][prediction]` returns the name of the specific class ->  `['setosa' 'versicolor' 'virginica'][0]` -> `'setosa'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['target_names']) # print all the names of the classes\n",
    "print(iris['target_names'][prediction]) # print the name of the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a prediction for an iris in the test data and compare it against its label (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test) # predict the class of the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Accuracy of Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of the model can be measured \n",
    "- How much of the sample matches the current dataset\n",
    "  -  fraction of flowers for which the right species was predicted\n",
    "- There are 2 ways of measuring accuracy, both of which return the same value:\n",
    "  - [Numpy Mean](#numpy-mean)\n",
    "  - [K-Nearest Neighbour](#k-nearest-neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred == y_test) # calculate the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Average number of `true` in the list is 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred == y_test) # print the result of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test) # calculate the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking If Both Method Return the Same Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_pred == y_test) == knn.score(X_test, y_test)) # check if the two methods give the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"iris_data.txt\") # load the data from the file\n",
    "print(X.shape) # print the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:3, :]) # print the first 3 rows of the data and all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking if the iris dataset is the same as the loaded dataset from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_equal(X, iris['data'])) # check if the data is the same as the one from the iris dataset\n",
    "print(np.mean(X == iris['data'])) # check percentage of data being the same as the one from the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Briefly explain the way `np.mean(y_pred == y_test)` is computed. \n",
    "It might help to run its part: `y_pred == y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing each element in the list `y_pred` to each element in list `y_test` which creates a new list with boolean values showing whether the elements were the same (true) or different (false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred == y_test) # print the result of the prediction for each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.mean()` will compute the mean number of true values in the list\n",
    "  - number of true values divided by total number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred == y_test) # calculate the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Draw the test error rate of the K Nearest Neighbours algorithm on the same training set against `K`. Use the same test set for all `K`.\n",
    "If you need to remember the scores you are getting for various `K`, you may use `NumPy` commands such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty(99) # create an empty array to store the results\n",
    "for K in range(1, 100): # iterate over all values of k\n",
    "\tknn = KNeighborsClassifier(n_neighbors = K) # create a new model\n",
    "\tknn.fit(X_train, y_train) # fit the model using the training data and training targets\n",
    "\tresults[K - 1] = knn.score(X_test, y_test) # calculate the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(99)+1,1-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Check that the dataset that you loaded from file in Section 5 is identical to the one that you loaded using load_iris in Section 1. You may want to use your answer to Exercise 1. If the two data sets are not identical, please explore the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the dataset imported from the `iris_data` file is the same as the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(X, iris['data']) # check if the data is the same as the one from the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check how much of the data matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X == iris['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns the indices for the locations where the data is different between the 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(X != iris['data'])) # print the indices of the data points that are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "In the context of conformal prediction, what is the minimal possible p-value for a training set of size 5?  (To two decimal places.)\n",
    "*0.2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "In conformal prediction, *validity* is achieved automatically (under the IID assumption).  But *achieving* efficiency is an art."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Different data sciences often use different assumptions about the data to reach their conclusions.\n",
    "- Which data science widely uses Gaussian assumptions? *Traditional statistics*\n",
    "- Which data science widely uses the IID assumption? *Mainstream machine learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Suppose a conformity measure A maps the sequence of observations\n",
    "(1,1), (2,0), (3,1)\n",
    "to the sequence of conformity scores\n",
    "0, 1, 0.\n",
    "Which sequence of conformity scores does A map\n",
    "(2,0), (3,1), (1,1)\n",
    "to?\n",
    "- *1, 0, 0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Suppose `y_pred` and `y_test` are vectors of the same length.  Then `y_pred==y_test` is a *vector* `(y_pred==y_test)+1` is a *vector*, `y_pred==y_test+1` is a *vector*, `(y_pred==y_test)[0]+1` is a *scalar*, and `np.mean(y_pred==y_test)` is a *scalar* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a list (vector) of comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred == y_test) # print the result of the prediction for each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a list (vector)\n",
    "- `+0` turns all the true and false predictions into integers\n",
    "  - True = 1\n",
    "  - False = 0\n",
    "- `+1` adds `1` to each prediction\n",
    "  - True = 2\n",
    "  - False = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_pred == y_test) + 1) # print the result of the prediction for each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a list (vector)\n",
    "- Each boolean element is an instance of an integer where true is 1 and false is 0\n",
    "  - Adding 1 will make true into 0 which is false and the same for false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_pred == y_test + 1)) # print the result of the prediction for each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `[0]` returns a single element from the list which means it is a scalar\n",
    "- The returned element is then incremented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_pred==y_test)[0]) \n",
    "print((y_pred==y_test)[0]+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `y_pred==y_test` returns a list of predictions which is then used to work out the mean making it scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "As you know, the scikit-learn function train_test_split splits the dataset (after shuffling) into two parts: training and test.  In what proportion does it do it?  (training:test)\n",
    "- *3:1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Answer the last question discussed in this week's slides.  Namely, the training set is:\n",
    "- positive samples: 0 and 1\n",
    "- negative samples: 10 and 11.\n",
    "The test sample is 12.  Compute (to one decimal place) the two p-values using the distance to the nearest sample of the same class as nonconformity score.\n",
    "- For postulated label +1 (positive), the p-value is *0.2*\n",
    "- For postulated label -1 (negative), the p-value is *1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "This question is about the iris dataset.  What is the error rate of the KNN with K=5 when using the standard train_test_split function? *0.026*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5) # create a new model\n",
    "knn.fit(X_train, y_train) # fit the model using the training data and training targets\n",
    "results = knn.score(X_test, y_test) # calculate the accuracy of the prediction\n",
    "print(\"Accuracy: \", results) # print the accuracy\n",
    "print(\"Error Rate: \", 1 - results) # print the error rate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a317dd932dec76e8fdc8987ca60af4062f347c78c20ca5292cf26c8b2836138"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
