{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\") # load data from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.       0.       0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708\n",
      "   1.       0.0376   0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223\n",
      "   0.84356 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357\n",
      "   0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.3409   0.42267 -0.54487\n",
      "   0.18641 -0.453    1.     ]\n",
      " [ 1.       0.       1.      -0.18829  0.93035 -0.36156 -0.10868 -0.93597\n",
      "   1.      -0.04549  0.50874 -0.67743  0.34432 -0.69707 -0.51685 -0.97515\n",
      "   0.05499 -0.62237  0.33109 -1.      -0.13151 -0.453   -0.18056 -0.35734\n",
      "  -0.20332 -0.26569 -0.20468 -0.18401 -0.1904  -0.11593 -0.16626 -0.06288\n",
      "  -0.13738 -0.02447 -1.     ]\n",
      " [ 1.       0.       1.      -0.03365  1.       0.00485  1.      -0.12062\n",
      "   0.88965  0.01198  0.73082  0.05346  0.85443  0.00827  0.54591  0.00299\n",
      "   0.83775 -0.13644  0.75535 -0.0854   0.70887 -0.27502  0.43385 -0.12062\n",
      "   0.57528 -0.4022   0.58984 -0.22145  0.431   -0.17365  0.60436 -0.2418\n",
      "   0.56045 -0.38238  1.     ]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `delimiter` defines the string to be used for separating values\n",
    "- Default `delimiter` of spaces is not used, but rather a comma `,` is used instead\n",
    "- `usecols` Which columns to read, with 0 being the first \n",
    "  - For example, `usecols = (1, 4, 5)` will extract the 2nd, 5th and 6th columns.\n",
    "  - `np.arrange(34)` creates a list (similar to list comprehension) up to 33\n",
    "  - This means that all the columns up to 33 will be extracted\n",
    "  - This is because the number of features (dependent variable vector) is 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\", usecols = np.arange(34)) # load data from file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that the labels are extracted, they can be stored in the variable `y` which represents the labels (dependent variable vector)\n",
    "- `dtype` of `int` specifies that the data to be stored needs to be integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\", usecols = np.arange(34), dtype='int') # load data from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0 -1 ... -1 -1 -1]\n",
      " [ 1  0  1 ... -1 -1 -1]\n",
      " [ 1  0  1 ... -1 -1 -1]\n",
      " ...\n",
      " [ 1  0 -1 ... -1 -1 -1]\n",
      " [ 1  0 -1 ... -1 -1 -1]\n",
      " [ 1  0 -1 ... -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.concatenate()` concatenates 2 sequences together\n",
    "- It only takes on argument for simple concatenations, a tuple containing the sequences to be concatenated\n",
    "  - This is not Pythonic design as it it possible to pass multiple arguments per parameter using tuple unpacking (`*args`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking if list comprehension is the same as `np.arange()` which is true\n",
    "- `np.arange()` generated an array, in this case to `10 ^ 6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print([x for x in range(10 ** 6)] in np.arange(10 ** 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.array([4])` creates an array with the single element 4 in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 arrays, `np.arange(10 ** 6)` and `np.array([4])` are concatenated together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.concatenate((np.arange(10 ** 6), np.array([4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Nearest Neighbour method depends on the ability to compute the minimum of an array of real numbers\n",
    "- In evaluating conformal predictors you may need to compute the largest p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `math.inf` is infinity\n",
    "- Infinity is the initial value of the minimum until something smaller/closer is found\n",
    "- For each element in the index, the current element is compared with the current minimum\n",
    "- If the current element is smaller/closer than the current minimum, then the current element becomes the new minimum\n",
    "- This process is repeated for the entire list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "current_minimum = math.inf # infinity\n",
    "for index, element in enumerate(my_array): # iterate over array\n",
    "\tif current_minimum > element: # check if current element is smaller than current minimum\n",
    "\t\tcurrent_minimum = element # update current minimum if necessary\n",
    "print(current_minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Describe briefly the array my_array in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It concatenates sequences together if they are on dimensional (vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Why did we repeat opening and closing parentheses for `np.concatenate()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because the function takes only argument when concatenating, a tuple containing the sequence types to be concatenated\n",
    "- This is actually not Pythonin as multiple arguments (sequence types) can be passed per parameter via tuple unpacking (`*args`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Why to you think the result for `sum(4 >= my array)` is 6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(sum(4 >= np.array([1, 2, 3, 4, 5, 6]))) # number of elements in array that are smaller than 4 \n",
    "print(sum(np.array([1, 2, 3, 4, 5, 6]))) # sum of all elements in array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `sum()` function has 2 capabilities:\n",
    "  - Compute the sum of all the elements\n",
    "  - Compute the number of elements that are within a certain range or comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Modify the code to also find the position of the minimum (i.e.,the index of the smallest element of the array; you may assume that there is a unique smallest element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "current_minimum = math.inf # infinity\n",
    "minimum_index = -1\n",
    "for index, element in enumerate(my_array): # iterate over array\n",
    "\tif current_minimum > element: # check if current element is smaller than current minimum\n",
    "\t\tcurrent_minimum = element # update current minimum if necessary\n",
    "\t\tminimum_index = index # update index of current minimum\n",
    "print(current_minimum, minimum_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5/6/7\n",
    "Write a function for computing the squared Euclidean norm of a vector represented as a NumPy array. You may use for loops. Your function should take two inputs, the array and its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_euclidean_norm(array: list) -> float:\n",
    "\treturn (math.sqrt(sum([x ** 2 for x in array])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "print(squared_euclidean_norm([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Give the definition of a conformity measure in the context of conformal prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A conformity measure is a function that quantifies the degree to which a prediction set contains the labels of the data points it was generated from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Give the definition of a nonconformity measure in the context of conformal prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A nonconformity measure is a function that quantifies the degree to which a prediction set does not contain the labels of the data points it was generated from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Define the notion of a conformal predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A conformal predictor is a function that takes as input a data point and a prediction set, and outputs a label that is predicted to be in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Compare and contrast nonconformity measures and conformity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A conformity measure quantifies the degree to which a prediction set contains the labels of the data points it was generated from\n",
    "- A nonconformity measure quantifies the degree to which a prediction set does not contain the labels of the data points it was generated from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "In the context of conformal prediction, what is the minimal possible p value for a training set of size `n`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimal possible p-value for a training set of size n is $$\\frac{1}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "In the context of conformal prediction, what are the possible p-values for a training set of size `n`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible p-values for a training set of size n are $$ \\frac{1}{n}, \\frac{2}{n}, \\frac{3}{n}, ..., 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "What is the main property of validity for conformal prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The main property of validity for conformal prediction is that it is guaranteed to never overfit the data\n",
    "- The coverage probability of the prediction sets should be at least equal to a preset confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "What is meant by the efficiency of a conformal predictor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The efficiency of a conformal predictor is a measure of how well it performs compared to other conformal predictors\n",
    "- Efficiency requires that the prediction sets should be as small as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "Give three examples of conformity measures based on the method of Nearest Neighbours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Euclidean distance\n",
    "- Manhattan distance\n",
    "- Minkowski distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "Consider the following training set in a multiclass classification problem:\n",
    "- samples of class A: (−1, 0) and (−1, −1);\n",
    "- samples of class B: (0, 0) and (0, 1);\n",
    "- samples of class C: (1, 1), (2, 1), and (2, 0).\n",
    "\n",
    "The test sample is `(1, 0)`. When answering the following questions, use the conformity measure defined as the distance to the nearest sample of a different class divided by the distance to the nearest sample of the same class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "What are the three p-values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "What are the point prediction, confidence, and credibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "Suppose the label of the text sample is B. Compute the average false p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "How are conformity measures used for computing p-values in the context of conformal prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conformity measures are used for computing p-values in the context of conformal prediction by quantifying the degree to which a prediction set contains the labels of the data points it was generated from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "How are nonconformity measures used for computing p-values in the context of conformal prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nonconformity measures are used for computing p-values in the context of conformal prediction by quantifying the degree to which a prediction set does NOT contain the labels of the data points it was generated from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "Give at least two examples of nonconformity measures suitable for regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Squared error\n",
    "- Absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "Discuss advantages and disadvantages of the conformity measures `αi =|yi − yˆi|` and `αi = |yi − yˆi| /σi`, where `ˆyi`\n",
    "is a prediction for `yi` and `σi > 0` is an estimate of its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Advantages:*\n",
    "- `αi =|yi − yˆi|` is that it is easier to compute than the measure `αi = |yi − yˆi| /σi`\n",
    "-` αi = |yi − yˆi| /σi` is that it is more accurate than the measure `αi =|yi − yˆi`\n",
    "\n",
    "\n",
    "*Disadvantage:*\n",
    "- `αi =|yi − yˆi|` is that it is less accurate than the measure `αi = |yi − yˆi| /σ`\n",
    "- `αi = |yi − yˆi|` /σi is that it is more difficult to compute than the measure `αi =|yi − yˆi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "How would you define a nonconformity measure based on the Nearest Neighbour algorithm and suitable for regression problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A nonconformity measure based on the Nearest Neighbour algorithm and suitable for regression problems can be defined as the squared error between the test point and its nearest neighbour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "How would you define a nonconformity measure based on the K Nearest Neighbours algorithm and suitable for regression problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A nonconformity measure based on the K Nearest Neighbours algorithm and suitable for regression problems can be defined as the average squared error between the test point and its K nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17\n",
    "Write a pseudocode (or Python code) for using a grid for conformal prediction in the problem of regression. You may assume that the prediction set is an interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Input:*\n",
    "- Training data: {(x1, y1), …, (xn, yn)}\n",
    "- Test data: {(x1, y1), …, (xm, ym)}\n",
    "- Parameters: grid_size\n",
    "\n",
    "*Output:* \n",
    "- Predicted labels for the test data\n",
    "\n",
    "*Steps:*\n",
    "1. For each test datapoint `(xi, yi)`, find the grid point that is closest to `xi`. Let this be point `j`. \n",
    "2. Compute the value of the nonconformity measure for `(xi, yi)` with respect to the training data using the grid point `j`. \n",
    "3. Output the predicted label for `(xi, yi)` as the label of the training datapoint with the smallest value of the nonconformity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19\n",
    "Briefly explain how conformal prediction can be used for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conformal prediction can be used for anomaly detection by considering the data points that are not in the prediction - set as anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20\n",
    "Define the point prediction, confidence, and credibility in the context of conformal prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **point prediction** is the label that is predicted to be in the set\n",
    "- The **confidence** is the proportion of times the label is predicted to be in the set\n",
    "- The **credibility** is the proportion of times the label is predicted to be in the set given that it is in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 21\n",
    "Let the size of the training set be `n`. Prove that the probability of error for a conformal predictor at significance level `ϵ = 1/(n+ 1)` does not exceed `ϵ`. (As usual in machine learning, you may make the IID assumption.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(error) = P(xp not in Cxp) = P(Z > 1) where Z ~ N(0,1)\n",
    "- P(error) = P(Z > 1) = 1-P(Z <= 1) = 1-Φ(1)\n",
    "  - where Φ is the CDF of the standard normal.\n",
    "- P(error) = 1-Φ(1) = 1 - (1/2 + 1/2erf(1/sqrt(2))) = 1- 0.68268949213708585\n",
    "- P(error) < 1/(n+1) for n = 1,2,3,...\n",
    "- P(error) < 0.5 for n >= 2\n",
    "- P(error) < 0.25 for n >= 3\n",
    "- P(error) < 0.2 for n >= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 22\n",
    "Let the size of the training set be n. Prove that the probability of error for a conformal predictor at significance level `ϵ = 2/(n+ 1)` does not exceed `ϵ`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(error) = P(xp not in Cxp) = P(Z > 1) where Z ~ N(0,1)\n",
    "- P(error) = P(Z > 1) = 1-P(Z <= 1) = 1-Φ(1)\n",
    "- where Φ is the CDF of the standard normal.\n",
    "- P(error) = 1-Φ(1) = 1 - (1/2 + 1/2erf(1/sqrt(2))) = 1- 0.68268949213708585\n",
    "- P(error) < 2/(n+1) for n = 1,2,3,...\n",
    "- P(error) < 1 for n >= 2\n",
    "- P(error) < 0.5 for n >= 3\n",
    "- P(error) < 0.4 for n >= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 23\n",
    "When is a p-value regarded as statistically significant? highly statistically\n",
    "significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- A p-value is generally regarded as statistically significant if it is less than `0.05`. A p-value is highly statistically significant if it is less than `0.01`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 24\n",
    "Define randomized p-values in the context of conformal prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized p-values are p-values that are randomly generated from a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 25\n",
    "Define randomized prediction sets in the context of conformal prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Randomized prediction sets are prediction sets that are generated by randomly permuting the labels of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 26\n",
    "State the main property of validity of randomized conformal predictors in the online mode of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The main property of validity of randomized conformal predictors in the online mode of prediction is that the prediction sets will eventually contain the correct label with high probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 27\n",
    "Define the average false p-value in the context of conformal prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The average false p-value is the expected value of the p-value over all possible values of the label."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('anaconda-pOKeClin-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d6ff4c17b0f926f3435e2604897e7630e7b57ea2fee9d98b1dac9eecef6094c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
